{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import Sastrawi\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.tag import CRFTagger\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentimen</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>oks kak semangat ya kalian kalian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>sekarang harus kaya orang bodoh lagi bodoh sangat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Begitu diumumkan lulus 100%, mereka semua suju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[USERNAME] [USERNAME] Katanya Bapak Reformasi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>macet macetan perut kosong akhirnya mampir dah...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  sentimen                                              tweet\n",
       "0   1         1                  oks kak semangat ya kalian kalian\n",
       "1   2         0  sekarang harus kaya orang bodoh lagi bodoh sangat\n",
       "2   3         1  Begitu diumumkan lulus 100%, mereka semua suju...\n",
       "3   4         0  [USERNAME] [USERNAME] Katanya Bapak Reformasi ...\n",
       "4   5         0  macet macetan perut kosong akhirnya mampir dah..."
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#membaca data\n",
    "raw_data = pd.read_csv(\"dataset/train_set.csv\", delimiter=\",\", encoding=\"Latin-1\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adalah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adanya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adapun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agaknya</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ada\n",
       "0   adalah\n",
       "1   adanya\n",
       "2   adapun\n",
       "3     agak\n",
       "4  agaknya"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read stopwords\n",
    "stopwords = pd.read_csv(\"dataset/stopwords.csv\")\n",
    "stopwords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisasi(tweet):\n",
    "    normal_tw = tweet.lower() #lowercase\n",
    "    normal_tw = re.sub('\\s+', ' ', normal_tw) # remove extra space\n",
    "    normal_tw = normal_tw.strip() #trim depan belakang\n",
    "    normal_tw = re.sub(r'[^\\w\\s]','',normal_tw) #buang punctuation\n",
    "    normal_regex = re.compile(r\"(.)\\1{1,}\", re.IGNORECASE) #regex huruf yang berulang kaya haiiii (untuk fitur unigram)\n",
    "    normal_tw = normal_regex.sub(r\"\\1\\1\", normal_tw) #buang huruf yang berulang\n",
    "    return normal_tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tweet):\n",
    "    special_list = ['username', 'url', 'sensitive-no']\n",
    "    token = nltk.word_tokenize(tweet)\n",
    "    token_afterremoval = []\n",
    "    for k in token:\n",
    "        if k not in stopwords and k not in special_list:\n",
    "            token_afterremoval.append(k)\n",
    "    str_clean = ' '.join(token_afterremoval)\n",
    "    return str_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "def stemming(tweet):\n",
    "    token = nltk.word_tokenize(tweet)\n",
    "    stem_kalimat = []\n",
    "    for k in token:\n",
    "       factory = StemmerFactory()\n",
    "       stemmer = factory.create_stemmer()\n",
    "       stem_kata = stemmer.stem(tweet)\n",
    "       stem_kalimat.append(stem_kata)   \n",
    "    stem_kalimat_str = ' '.join(stem_kalimat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(list_tweet):\n",
    "    # id tweet incremental, jadi simpen aja list berurut\n",
    "    tweet_clean = []\n",
    "    for tw in list_tweet:\n",
    "        normal_tweet = normalisasi(tw)\n",
    "        nosw_tweet = remove_stopwords(normal_tweet)\n",
    "        \n",
    "        stem_tweet = stemming(nosw_tweet)\n",
    "        tweet_clean.append(nosw_tweet)\n",
    "    return tweet_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ekstraksiBoW(tweet):\n",
    "    unigram = CountVectorizer(ngram_range=(1,1), max_features=2000)\n",
    "    unigram_matrix = unigram.fit_transform(np.array(tweet)).todense()\n",
    "    nama_fitur = unigram.get_feature_names()\n",
    "    return unigram_matrix, nama_fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ekstraksiSentimen(list_tweet):\n",
    "    pos = pd.read_csv('dataset/positif_vania.txt', header=None, names=['pos'])\n",
    "    list_pos = pos['pos'].tolist()\n",
    "    neg = pd.read_csv('dataset/negatif_vania.txt', header=None, names=['neg'])\n",
    "    list_neg = neg['neg'].tolist()\n",
    "\n",
    "    fitur_sentimen_all = []\n",
    "    for tweet in list_tweet:\n",
    "        ##inisiasi value\n",
    "        emosi = [\"positif\", \"negatif\"]\n",
    "        value = [0,0]\n",
    "        emosi_value = {}\n",
    "        for i in range(len(emosi)):\n",
    "            emosi_value[emosi[i]] = value[i]\n",
    "    \n",
    "        list_kata = tweet.split()\n",
    "        for k in list_kata:\n",
    "            if k in list_pos:\n",
    "                emosi_value[\"positif\"] += 1\n",
    "            if k in list_neg:\n",
    "                emosi_value[\"negatif\"] += 1\n",
    "\n",
    "\n",
    "        fitur_sentimen_perkalimat = list(emosi_value.values())\n",
    "        fitur_sentimen_all.append(fitur_sentimen_perkalimat)\n",
    "\n",
    "    return fitur_sentimen_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ekstraksiPOS(list_tweet):\n",
    "    ct = CRFTagger()\n",
    "    ct.set_model_file(\"dataset/all_indo_man_tag_corpus_model.crf.tagger\")\n",
    "    pos_feat_list = []\n",
    "    count_tag = []\n",
    "    for tweet in list_tweet:\n",
    "        token = nltk.word_tokenize(tweet)\n",
    "        tag = ct.tag_sents([token])\n",
    "        flat_tag = [item for sublist in tag for item in sublist]\n",
    "        pos_count = Counter([j for i,j in flat_tag])\n",
    "        pos_feat = (pos_count['JJ'], pos_count['NEG'])\n",
    "        pos_feat_list.append(pos_feat)\n",
    "\n",
    "    return pos_feat_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpen state sampe stemming dulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_state(data_tweets):\n",
    "    # create preprocessing state\n",
    "    clean_data = raw_data.copy(deep=True)\n",
    "    clean_data['tweet'] = data_tweets\n",
    "    with open('dataset/preprocess_state.csv', 'w') as state_file:\n",
    "        state_file.write(clean_data.to_csv(index=False))\n",
    "    return clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentimen</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>oks kak semangat ya kalian kalian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>sekarang harus kaya orang bodoh lagi bodoh sangat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>begitu diumumkan lulus 100 mereka semua sujud ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>katanya bapak reformasi dan demokrasi di neger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>macet macetan perut kosong akhirnya mampir dah...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  sentimen                                              tweet\n",
       "0   1         1                  oks kak semangat ya kalian kalian\n",
       "1   2         0  sekarang harus kaya orang bodoh lagi bodoh sangat\n",
       "2   3         1  begitu diumumkan lulus 100 mereka semua sujud ...\n",
       "3   4         0  katanya bapak reformasi dan demokrasi di neger...\n",
       "4   5         0  macet macetan perut kosong akhirnya mampir dah..."
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_tweet = raw_data['tweet']\n",
    "clean_tweets = preprocessing(raw_tweet)\n",
    "create_state(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3462, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentimen</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>oks kak semangat ya kalian kalian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>sekarang harus kaya orang bodoh lagi bodoh sangat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>begitu diumumkan lulus 100 mereka semua sujud ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>katanya bapak reformasi dan demokrasi di neger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>macet macetan perut kosong akhirnya mampir dah...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  sentimen                                              tweet\n",
       "0   1         1                  oks kak semangat ya kalian kalian\n",
       "1   2         0  sekarang harus kaya orang bodoh lagi bodoh sangat\n",
       "2   3         1  begitu diumumkan lulus 100 mereka semua sujud ...\n",
       "3   4         0  katanya bapak reformasi dan demokrasi di neger...\n",
       "4   5         0  macet macetan perut kosong akhirnya mampir dah..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Membaca data menggunakan pandas\n",
    "#import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import Sastrawi\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from nltk.tag import CRFTagger\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "raw_data = pd.read_csv('dataset/preprocess_state.csv', encoding = \"Latin-1\")\n",
    "print(raw_data.shape)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
